ifndef::imagesdir[]
:imagesdir: ../images
:codedir: ../../src
endif::[]

= HashMap
(((HashMap)))
(((HashTable)))
(((Data Structures, Non-Linear, HashMap)))
A HashMap is a Map implementation. HashMaps are composed of two things:
1) a _hash function_ and
2) a bucket _array_ to store values.

Before going into the implementation details let‚Äôs give an overview of how it works. Let‚Äôs say we want to keep a tally of things and animals:

.HashMap example
[source, javascript]
----
include::{codedir}/data-structures/maps/hash-maps/hash-map.js[tag=snippet, indent=0]
----

How are the keys mapped to their values?
Using a hash function. Here‚Äôs an illustration:

.Internal HashMap representation
image:image41.png[image,width=528,height=299]


.This is the main idea:
1.  We use a *hash function* to transform the keys (e.g., dog, cat, rat, ‚Ä¶) into an array index. This _array_ is called *bucket*.
2.  The bucket holds the values or list of values in case of collisions.

In the illustration, we have a bucket size of 10. In bucket 0, we have a collision. Both `cat` and `art` keys map to the same bucket even thought their hash codes are different.

In a HashMap, a *collision* is when different keys lead to the same index. They are nasty for performance since it can reduce the search time from *O(1)* to *O(n)*.

Having a big bucket size can avoid a collision but also can waste too much memory. We are going to build an _optimized_ HashMap that re-sizes itself when it is getting full. This auto-resizing avoids collisions and don't need to allocate too much memory upfront. Let‚Äôs start with the *hash function*.

== Designing an optimized hash function

To minimize collisions, we need to create an excellent hash function.

IMPORTANT: A *perfect* hash function is one that assigns a unique array index for every different key.

It‚Äôs no practical and memory-wise wasteful to have a perfect hash function, so we are going to shoot for a cost-effective hash function instead.

.To recap:
- A hash function converts keys into array indices.
- A hash function is composed of two parts:
1.  *Hash Code*: maps any key into an integer (unbonded)
2.  *Compression function*: maps an arbitrary integer to integer in the range of [0‚Ä¶ BUCKET_SIZE -1].

Before doing a great hash function, let's see what a lousy hash function looks like. üòâ

=== Analysing collisions on bad hash code functions

The goal of a hash code function is to convert any value given into a positive integer ‚Äî a common way to accomplish with summing each string‚Äôs Unicode value.

.Na√Øve hashing function implementation
[source, javascript]
----
include::{codedir}/data-structures/maps/hash-maps/hashing.js[tag=naiveHashCode, indent=0]
----


This function uses `codePointAt` to get the Unicode value of a character. E.g., `a` has a value of 97, `A` is 65, even https://en.wikipedia.org/wiki/Emoji#Unicode_blocks[emojis have codes]; ‚Äú[big]#üòÅ#‚Äù is `128513`.

.JavaScript built-in `string.charCodeAt` vs. `string.codePointAt`
****
The `charCodeAt()` method returns an integer between `0` and `65535` representing the UTF-16 code unit at the given index. However, it doesn‚Äôt play nice with Unicode, so it‚Äôs better to use `codePointAt` instead.

The `codePointAt()` method returns a non-negative integer that is the Unicode code point value.
****
With this function we have the can convert some keys to numbers as follows:

.Hashing examples
[source, javascript]
----
include::{codedir}/data-structures/maps/hash-maps/hashing.js[tag=naiveHashCodeExamples, indent=0]
----

Notice that `rat` and `art` have the same hash code! These are collisions that we need to solve.

Collisions happened because we are adding the letter's Unicode and are not taking the order into account nor the type. We can do better by offsetting the character value based on their position in the string. We can also add the object type, so number `10` produce different output than string `'10'`.

.Hashing function implementation that offset character value based on the position
[source, javascript]
----
include::{codedir}/data-structures/maps/hash-maps/hashing.js[tag=hashCodeOffset, indent=0]
----

Since Unicode uses 20 bits, we can offset each character by 20 bits based on the position.

.JavaScript built-in `BigInt`
****
BigInt allows operating beyond the maximum safe limit of integers.

[source, javascript]
----
Number.MAX_SAFE_INTEGER // => 9,007,199,254,740,991
----

BigInt has no virtual limits (until you run out of physical memory). It uses the suffix `n`.

[source, javascript]
----
1n + 3n === 4n
----
****

As you can imagine, summing 20bits per letter leads to a humongous number! That's the case even for three letters words. We are using `BigInt`, so it doesn‚Äôt overflow.

.Verifying there's not hashing code duplicates
[source, javascript]
----
include::{codedir}/data-structures/maps/hash-maps/hashing.js[tag=hashCodeOffsetExample, indent=0]
----

We don‚Äôt have duplicates anymore! If the keys have different content or type, they have a different hash code. However, we need to represent these unbounded integers to finite buckets in an array. We do that using *compression function*. This function can be as simple as `% BUCKET_SIZE`.

However, there‚Äôs an issue with the last implementation. It doesn‚Äôt matter how enormous (and different) is the hash code number if we at the end use the modulus to get an array index. The part of the hash code that truly matters is the last bits.

.Look at this example with a bucket size of 4.
[source, javascript]
----
10 % 4 //‚Ü™Ô∏è 2
20 % 4 //‚Ü™Ô∏è 0
30 % 4 //‚Ü™Ô∏è 2
40 % 4 //‚Ü™Ô∏è 0
50 % 4 //‚Ü™Ô∏è 2
----

All the hash codes are different and still we get many collisions! [big]#üò±#

Based on numbers properties, using a prime number as the modulus produce fewer collisions.

.Let‚Äôs see what happens if the bucket size is a prime number:
[source, javascript]
----
10 % 7 //‚Ü™Ô∏è 3
20 % 7 //‚Ü™Ô∏è 6
30 % 7 //‚Ü™Ô∏è 2
40 % 7 //‚Ü™Ô∏è 4
50 % 7 //‚Ü™Ô∏è 1
----

Now it‚Äôs more evenly distributed!! [big]#üòéüëç#

.So, to sum up:
* Bucket size should always be a *prime number*, so data is distributed more evenly and minimized collisions.
* Hash code doesn‚Äôt have to be too big. At the end what matters is the few last digits.

Let‚Äôs design a better HashMap with what we learned.

=== Implementing an optimized hash function

We are going to use a battle-tested non-cryptographic hash function called FNV Hash.

.FNV (Fowler/Noll/Vo) Hash
****
It is a non-cryptographic hash function designed to be fast while maintaining a low collision rate. The high dispersion of the FNV hashes makes them well suited for hashing nearly identical strings such as URLs, keys, IP addresses, zip codes, and others.
****


Take a look at the following function:

.Optimal Hash function
[source, javascript]
----
include::{codedir}/data-structures/maps/hash-maps/hash-map.js[tag=hashFunction, indent=0]
----

Is somewhat similar to what we did before, in the sense that we use each letter‚Äôs Unicode is used to compute the hash. The difference is:

1.  We are using the XOR bitwise operation (`^`) to produce an *avalanche effect*, where a small change in two strings produces completely different hash codes. E.g.

.Hash Code example using FVN1a
[source, javascript]
----
hashCode('cat') //‚Ü™Ô∏è 4201630708
hashCode('cats') //‚Ü™Ô∏è 3304940933
----

A one letter change produce a very different output.

We are using the FVN-1a prime number (`16777619`) and the offset (`2166136261`) to reduce collisions even further. If you are curious where these numbers come from check out this http://bit.ly/fvn-1a[link].

FVN-1a hash function is a good trade-off between speed and collision prevention.

Now that we have a proper hash function. Let‚Äôs move on with the rest of the HashMap implementation.

== Implementing a HashMap in JavaScript

Let‚Äôs start by creating a class and its constructor to initialize the hash map. We are going to have an array called `buckets` to hold all the data.

.HashMap's constructor
[source, javascript]
----
class HashMap {
include::{codedir}/data-structures/maps/hash-maps/hash-map.js[tag=constructorPartial, indent=2]
    this.buckets = new Array(this.initialCapacity);
    this.size = 0;
    this.collisions = 0;
  }

include::{codedir}/data-structures/maps/hash-maps/hash-map.js[tag=getLoadFactor, indent=2]
}
----

Notice that we are also keeping track of collisions (for benchmarking purposes) and a load factor. *The load factor* measures how full the hash map is. We don‚Äôt want to be fuller than 75%. If the HashMap is getting too full, then we are going to fix it doing a *rehash* (more on that later).

=== Inserting elements in a HashMap

To insert values into a HashMap, we first convert the *key* into an *array index* using the hash and compression function. Each bucket of the array will have an object with the shape of `{key, value}`.

In code, it looks like this:

.HashMap's set method
[source, javascript]
----
include::{codedir}/data-structures/maps/hash-maps/hash-map.js[tag=set, indent=0]
----
// There are multiple scenarios for inserting key/values in a HashMap:
<1>  Key doesn‚Äôt exist yet, so we create the new key/value pair.
<2>  Key already exists, then we will replace the value.
<3>  Key doesn‚Äôt exist, but the bucket already has other data, this is a collision! We push the new element to the bucket.
<4> To keep insertion order, we keep track of the order of the keys using `keysTrackerArray` and `keysTrackerIndex`.

Notice, that we are using a function called `getEntry` to check if the key already exists. It gets the index of the bucket corresponding to the key and then checks if the entry with the given key exists. We are going to implement this function in a bit.

=== Getting values out of a HashMap

For getting values out of the Map, we do something similar to inserting. We convert the key into an `index` using the hash function, then we that `index` we look for the value in the bucket.

.HashMap's getEntry method
[source, javascript]
----
include::{codedir}/data-structures/maps/hash-maps/hash-map.js[tag=getEntry, indent=0]
----
<1> Convert key to an array index.
<2> If the bucket is empty create a new linked list
<3> Use Linked list's <<Searching by value>> method to find value on the bucket.
<4> Return `bucket` and `entry` if found.

With the help of the `getEntry` method, we can do the `HashMap.get` and `HashMap.has` methods:

.HashMap's get method
[source, javascript]
----
include::{codedir}/data-structures/maps/hash-maps/hash-map.js[tag=get, indent=0]
----

and also,

.HashMap's has method
[source, javascript]
----
include::{codedir}/data-structures/maps/hash-maps/hash-map.js[tag=has, indent=0]
----

For `HashMap.has` we only care if the value exists or not, while that for `HashMap.get` we want to return the value or `undefined` if it doesn‚Äôt exist.

=== Deleting from a HashMap

Removing items from a HashMap is not too different from what we did before.

.HashMap's delete method
[source, javascript]
----
include::{codedir}/data-structures/maps/hash-maps/hash-map.js[tag=delete, indent=0]
----

If the bucket doesn‚Äôt exist or is empty, we don't have to do anything else. If the value exists, we use the
https://github.com/amejiarosario/dsa.js/blob/7694c20d13f6c53457ee24fbdfd3c0ac57139ff4/src/data-structures/linked-lists/linked-list.js#L218[`LinkedList.remove` ]
method.

== Rehashing a HashMap

Rehashing is a technique to minimize collisions when a hash map is getting full. It doubles the size of the map and recomputes all the hash codes and insert data in the new buckets.

When we increase the map size, we try to find the next prime. We explained that keeping the bucket size a prime number is beneficial for minimizing collisions.

.HashMap's rehash method
[source, javascript]
----
include::{codedir}/data-structures/maps/hash-maps/hash-map.js[tag=rehash, indent=0]
----

In the
https://github.com/amejiarosario/dsa.js/blob/7694c20d13f6c53457ee24fbdfd3c0ac57139ff4/src/data-structures/maps/hash-maps/primes.js#L33[prime.js] file you can find the implementation for finding the next prime. Also, you can see the full HashMap implementation on this file: https://github.com/amejiarosario/dsa.js/blob/f69b744a1bddd3d99243ca64b3ad46f3f2dd7342/src/data-structures/maps/hash-maps/hash-map.js#L1[hashmap.js]

== HashMap time complexity

Hash Map it‚Äôs very optimal for searching values by key in constant time *O(1)*. However, searching by value is not any better than an array since we have to visit every value *O(n)*.
(((Tables, Non-Linear DS, HashMap complexities)))

// tag::table[]
.Time complexity for a Hash Map
|===
.2+.^s| Data Structure 2+^s| Searching By .2+^.^s| Insert .2+^.^s| Delete .2+^.^s| Space Complexity
^|_Index/Key_ ^|_Value_
| Hash Map (na√Øve) ^|O(n) ^|O(n) ^|O(n) ^|O(n) ^|O(n)
| Hash Map (optimized) ^|O(1)* ^|O(n) ^|O(1)* ^|O(1)* ^|O(1)*
|===
{empty}* = Amortized run time. E.g. rehashing might affect run time.
// end::table[]

indexterm:[Runtime, Linear]
As you can notice we have amortized times since, in the unfortunate case of a rehash, it will take O(n) while it resizes. After that, it will be *O(1)*.
